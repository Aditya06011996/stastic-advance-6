{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe33a403-550d-4a53-9816-6118287dc496",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3db55e7-64ed-401d-b7ea-71f394dfcdc4",
   "metadata": {},
   "source": [
    "Ans - Analysis of Variance (ANOVA) is a statistical technique used to compare means among three or more groups. It makes several assumptions about the data, and violations of these assumptions can impact the validity of the results. Here are the key assumptions of ANOVA and examples of violations:\n",
    "\n",
    "**Assumption 1: Independence:** This assumption states that observations within each group are independent of each other. Violations of this assumption can occur when data points within a group are not independent, such as in a repeated-measures design where the same subjects are used in all groups. In such cases, a repeated-measures ANOVA or mixed-effects model may be more appropriate.\n",
    "\n",
    "**Assumption 2: Normality:** ANOVA assumes that the residuals (the differences between the observed values and the group means) are normally distributed within each group. Violations of this assumption can lead to incorrect p-values and confidence intervals. You can check for normality using graphical methods like Q-Q plots or statistical tests like the Shapiro-Wilk test. If the data is not normal, transforming the data (e.g., using a log transformation) or using non-parametric tests like the Kruskal-Wallis test may be appropriate.\n",
    "\n",
    "**Assumption 3: Homogeneity of Variances (Homoscedasticity):** ANOVA assumes that the variances of the residuals are equal across all groups. Violations of this assumption, known as heteroscedasticity, can lead to unequal group variances and affect the validity of the F-test. You can check for homogeneity of variances using statistical tests like Levene's test or by visually inspecting scatterplots of residuals. If variances are not equal, you may need to use a Welch's ANOVA or a transformation of the data.\n",
    "\n",
    "**Assumption 4: Interval or Ratio Data:** ANOVA assumes that the dependent variable is measured on an interval or ratio scale. It is not appropriate for nominal or ordinal data. Violating this assumption can lead to incorrect results. In such cases, non-parametric tests like the Kruskal-Wallis test (for ordinal data) or chi-square tests (for nominal data) should be used.\n",
    "\n",
    "**Assumption 5: Random Sampling:** ANOVA assumes that the samples are drawn randomly from the population. Violations of this assumption can introduce bias into the results. Non-random sampling can lead to results that do not generalize well to the broader population.\n",
    "\n",
    "**Assumption 6: Homogeneity of Groups:** ANOVA assumes that the groups being compared are roughly equal in size. Extreme imbalances in group sizes can affect the power of the ANOVA and may require adjustments or alternative tests.\n",
    "\n",
    "**Assumption 7: Absence of Interactions:** ANOVA assumes that there are no significant interactions between the independent variables (factors). Interactions occur when the effect of one factor depends on the level of another factor. Violations of this assumption can complicate the interpretation of main effects.\n",
    "\n",
    "It's essential to check these assumptions before conducting ANOVA to ensure the validity of the results. If violations are detected, appropriate adjustments or alternative statistical tests should be considered to account for these issues and make more reliable inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e24f23-458f-41ed-bd35-f6f9d2ca01c0",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e0372-9016-49bb-ae4b-ee2921a3359a",
   "metadata": {},
   "source": [
    "Ans - Analysis of Variance (ANOVA) is a statistical technique used to compare means among three or more groups. There are three main types of ANOVA, each designed for specific situations:\n",
    "\n",
    "1. **One-Way ANOVA (One-Factor ANOVA):**\n",
    "   - **Use:** One-Way ANOVA is used when you have one independent variable (factor) with more than two levels or groups, and you want to determine if there are any statistically significant differences in the means of the dependent variable among these groups.\n",
    "   - **Example:** Suppose you want to compare the mean exam scores of students who attended three different prep courses (Course A, Course B, Course C) to see if one course leads to significantly different exam performance compared to the others.\n",
    "\n",
    "2. **Two-Way ANOVA (Two-Factor ANOVA):**\n",
    "   - **Use:** Two-Way ANOVA is used when you have two independent variables (factors), and you want to examine how these two factors interact with each other to influence the dependent variable. It can help you assess the main effects of each factor and whether there is an interaction effect between them.\n",
    "   - **Example:** Imagine you are studying the effects of both gender (Male vs. Female) and age group (Young Adults vs. Middle-aged Adults vs. Senior Adults) on a health outcome like blood pressure. Two-Way ANOVA would allow you to determine if there are significant differences due to gender, age group, and whether there is an interaction effect between gender and age group.\n",
    "\n",
    "3. **Repeated Measures ANOVA (Within-Subjects ANOVA):**\n",
    "   - **Use:** Repeated Measures ANOVA is used when you have collected measurements on the same subjects under multiple conditions or time points. It is used to examine changes within subjects over time or across different conditions.\n",
    "   - **Example:** Suppose you are studying the effect of a new drug on the blood pressure of the same group of patients at three different time points (baseline, after one month, after three months). Repeated Measures ANOVA would be appropriate to determine if there are significant changes in blood pressure over time due to the drug.\n",
    "\n",
    "In addition to these three main types, there are variations and extensions of ANOVA, such as:\n",
    "\n",
    "- **Multivariate Analysis of Variance (MANOVA):** Used when you have multiple dependent variables and multiple independent variables to assess whether there are significant differences across groups while considering correlations among dependent variables.\n",
    "\n",
    "- **Analysis of Covariance (ANCOVA):** Combines aspects of ANOVA and regression, where it assesses group differences while controlling for the influence of one or more continuous covariates.\n",
    "\n",
    "- **Mixed-Design ANOVA:** Combines elements of both Two-Way ANOVA and Repeated Measures ANOVA. It's used when you have multiple factors, including one or more within-subjects (repeated measures) factors and one or more between-subjects factors.\n",
    "\n",
    "The choice of which ANOVA to use depends on the specific research design, the number of factors and levels, and the nature of the data being analyzed. Careful consideration of the experimental or observational design is crucial in selecting the appropriate type of ANOVA to answer the research question accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65320577-f0f3-409b-a3e2-a29b60765675",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174d48b-6693-4e78-b7b1-f3952321e625",
   "metadata": {},
   "source": [
    "Ans - The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps us understand how the total variability in a dataset is divided into different sources or components of variability. ANOVA aims to explain the total variance observed in a dependent variable by decomposing it into two main components: systematic variance and error variance. Understanding this partitioning is crucial for several reasons:\n",
    "\n",
    "1. **Identifying Sources of Variation:** ANOVA helps us identify which factors or independent variables (and their interactions) are responsible for the observed variation in the dependent variable. By partitioning the variance, we can determine how much of the total variability can be attributed to these factors and whether their effects are statistically significant.\n",
    "\n",
    "2. **Hypothesis Testing:** ANOVA allows us to test hypotheses about the significance of group differences. By comparing the systematic variance (variation between groups) to the error variance (variation within groups), ANOVA calculates an F-statistic, which is used to assess whether the observed group differences are likely due to factors of interest or if they could have occurred by chance.\n",
    "\n",
    "3. **Effect Size Estimation:** Understanding the partitioning of variance helps in quantifying the size of the effects of the independent variables on the dependent variable. Effect size measures, such as eta-squared (η²) or partial eta-squared (η²_p), are derived from the partitioned variance and provide information about the practical significance of the results.\n",
    "\n",
    "The partitioning of variance in ANOVA typically involves three key components:\n",
    "\n",
    "1. **Total Variance (Total SS):** This is the total variability in the dependent variable across all observations. It represents the sum of squared differences between each data point and the overall mean of the data. Mathematically, Total SS = Sum of (X - Grand Mean)².\n",
    "\n",
    "2. **Between-Groups Variance (Between-Groups SS):** This component represents the variability in the dependent variable that can be attributed to the differences between the group means. It measures the effect of the independent variable(s) on the dependent variable. Mathematically, Between-Groups SS = Sum of (Group Mean - Grand Mean)².\n",
    "\n",
    "3. **Within-Groups Variance (Within-Groups SS or Error SS):** This component represents the variability in the dependent variable that cannot be explained by the differences between the group means. It reflects the random variation and measurement error within each group. Mathematically, Within-Groups SS = Sum of (X - Group Mean)².\n",
    "\n",
    "The importance of understanding this partitioning lies in the ability to draw valid conclusions about the relationships between independent and dependent variables. ANOVA helps researchers assess whether the observed differences among groups are statistically significant and not merely the result of chance or random variability. It quantifies the proportion of variance explained by the factors under investigation and aids in determining the practical significance of these effects. This knowledge is crucial for making informed decisions in various fields, including research, experimental design, and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab1c42-b414-4613-8c04-0b4cdbac4b5d",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d3742-5b0c-4ab4-b74f-b9072ff3f931",
   "metadata": {},
   "source": [
    "Ans - In a one-way Analysis of Variance (ANOVA), you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) using Python. You would typically use libraries like NumPy and SciPy to perform these calculations. Here's how you can do it step by step:\n",
    "\n",
    "Assume you have a dataset with a dependent variable (e.g., 'y') and a categorical independent variable (e.g., 'group')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c1f335-c578-4bf9-a99f-2619b6ff11a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 90.0\n",
      "Explained Sum of Squares (SSE): 84.0\n",
      "Residual Sum of Squares (SSR): 6.0\n",
      "Degrees of Freedom - Total: 5, Group: 2, Error: 3\n",
      "Mean Squares - Group: 42.0, Error: 2.0\n",
      "F-statistic: 21.0\n",
      "P-value: 0.017213259316477436\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data\n",
    "group = np.array(['A', 'A', 'B', 'B', 'C', 'C'])\n",
    "y = np.array([12, 14, 9, 11, 18, 20])\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = {}\n",
    "for g in np.unique(group):\n",
    "    group_means[g] = np.mean(y[group == g])\n",
    "\n",
    "# Calculate the grand mean\n",
    "grand_mean = np.mean(y)\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "SST = np.sum((y - grand_mean)**2)\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "SSE = np.sum([len(group[group == g]) * (group_means[g] - grand_mean)**2 for g in np.unique(group)])\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "# Degrees of Freedom\n",
    "df_total = len(y) - 1\n",
    "df_group = len(np.unique(group)) - 1\n",
    "df_error = df_total - df_group\n",
    "\n",
    "# Mean Squares\n",
    "MS_group = SSE / df_group\n",
    "MS_error = SSR / df_error\n",
    "\n",
    "# F-statistic\n",
    "F = MS_group / MS_error\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - stats.f.cdf(F, df_group, df_error)\n",
    "\n",
    "print(f\"Total Sum of Squares (SST): {SST}\")\n",
    "print(f\"Explained Sum of Squares (SSE): {SSE}\")\n",
    "print(f\"Residual Sum of Squares (SSR): {SSR}\")\n",
    "print(f\"Degrees of Freedom - Total: {df_total}, Group: {df_group}, Error: {df_error}\")\n",
    "print(f\"Mean Squares - Group: {MS_group}, Error: {MS_error}\")\n",
    "print(f\"F-statistic: {F}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14892068-04db-4f70-839a-98b138e010c6",
   "metadata": {},
   "source": [
    "This code calculates SST, SSE, and SSR for a one-way ANOVA and also computes the F-statistic and p-value to test the null hypothesis that there are no significant differences between the group means. You can adjust the 'group' and 'y' arrays to match your dataset. The code assumes that your data is organized in such a way that each data point corresponds to a specific group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaba930-5718-4087-9b03-958bc3d6285a",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190e083-7307-456d-9359-2b9c8dd818f6",
   "metadata": {},
   "source": [
    "Ans - In a two-way Analysis of Variance (ANOVA), you can calculate the main effects and interaction effects using Python. A two-way ANOVA examines the influence of two independent variables (factors) on a dependent variable and assesses both the main effects of each factor and the interaction effect between them. You can use libraries like NumPy and SciPy to perform these calculations. Here's how to calculate the main effects and interaction effect:\n",
    "\n",
    "Assume you have a dataset with a dependent variable (e.g., 'y'), two categorical independent variables (e.g., 'factor1' and 'factor2'), and you want to calculate the main effects and interaction effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4321833-e656-4358-83eb-50cd1a3978de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor 1: 63.000000000000156\n",
      "Main Effect of Factor 2: 11.571428571428559\n",
      "Interaction Effect: 0.14285714285714057\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'factor1': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n",
    "        'factor2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "        'y': [10, 12, 15, 18, 9, 11, 14, 16]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "formula = 'y ~ C(factor1) + C(factor2) + C(factor1):C(factor2)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_factor1 = anova_table.loc['C(factor1)', 'F']\n",
    "main_effect_factor2 = anova_table.loc['C(factor2)', 'F']\n",
    "interaction_effect = anova_table.loc['C(factor1):C(factor2)', 'F']\n",
    "\n",
    "# Print results\n",
    "print(\"Main Effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d5b48-f0ce-490e-9e93-57bf195d31f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this code:\n",
    "\n",
    "1. We create a sample dataset with 'factor1', 'factor2', and 'y'.\n",
    "\n",
    "2. We fit a two-way ANOVA model using the `ols` function from the `statsmodels` library.\n",
    "\n",
    "3. The formula for the ANOVA model specifies both main effects and the interaction effect: `y ~ C(factor1) + C(factor2) + C(factor1):C(factor2)`.\n",
    "\n",
    "4. We use `sm.stats.anova_lm` to obtain the ANOVA table.\n",
    "\n",
    "5. We extract the F-statistics for the main effect of 'factor1', main effect of 'factor2', and the interaction effect from the ANOVA table.\n",
    "\n",
    "6. Finally, we print the main effects and interaction effect.\n",
    "\n",
    "This code will give you the main effects of each factor and the interaction effect between the two factors in a two-way ANOVA. You can adjust the dataset and column names according to your specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805792b7-17d4-407e-9c71-c00e0b5eb889",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3377f-fa79-4617-907d-c9959604ca8e",
   "metadata": {},
   "source": [
    "Ans - In a one-way Analysis of Variance (ANOVA), the F-statistic and p-value are used to assess whether there are significant differences in the means of the groups being compared. In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02. To interpret these results, follow these steps:\n",
    "\n",
    "1. **Null Hypothesis (H0):** The null hypothesis in ANOVA is that there are no significant differences in the means of the groups. In other words, all group means are equal.\n",
    "\n",
    "2. **Alternative Hypothesis (Ha):** The alternative hypothesis is that there are significant differences in the means of the groups. At least one group mean is different from the others.\n",
    "\n",
    "3. **F-Statistic:** The F-statistic is a measure of the ratio of the explained variance (between-group variance) to the unexplained variance (within-group variance). A higher F-statistic suggests that the group means are more different from each other relative to the variability within each group.\n",
    "\n",
    "4. **P-value:** The p-value associated with the F-statistic tells you the probability of observing the obtained F-statistic (or a more extreme value) if the null hypothesis is true. In your case, a p-value of 0.02 indicates that there is a 2% chance of obtaining the observed F-statistic under the assumption that there are no real differences in group means.\n",
    "\n",
    "Now, let's interpret the results:\n",
    "\n",
    "- Since the p-value (0.02) is less than the typical significance level (e.g., 0.05), you would reject the null hypothesis (H0). This means that you have evidence to suggest that there are significant differences in the means of the groups.\n",
    "\n",
    "- The F-statistic (5.23) provides a measure of how much the group means differ relative to the variability within each group. A larger F-statistic suggests larger differences between the group means.\n",
    "\n",
    "- Based on the results, you can conclude that there are statistically significant differences between at least some of the groups. However, the ANOVA itself does not tell you which specific groups are different from each other; it only indicates that at least one group differs from the rest. To determine which groups are different, you would typically perform post hoc tests or pairwise comparisons (e.g., Tukey's HSD, Bonferroni correction) to pinpoint where the differences exist.\n",
    "\n",
    "In summary, the F-statistic of 5.23 with a p-value of 0.02 suggests that there are significant differences in the means of the groups. Further analyses would be needed to identify which specific groups differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c388a16-f25c-40b6-82d5-f6f69ec6fc19",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af107a7a-3e9a-45ca-8ff2-669193611f1b",
   "metadata": {},
   "source": [
    "Ans - Handling missing data in a repeated measures Analysis of Variance (ANOVA) is important because missing data can introduce bias and reduce the accuracy and power of your analysis. There are various methods for handling missing data in repeated measures ANOVA, each with its own potential consequences. Here are some common methods and their implications:\n",
    "\n",
    "1. **Complete Case Analysis (Listwise Deletion):** This method involves removing cases with any missing data from the analysis. It's straightforward but can lead to a reduction in sample size, potentially introducing bias if the missing data is not missing completely at random (MCAR). The consequence is a loss of statistical power and potential bias in parameter estimates.\n",
    "\n",
    "2. **Mean Imputation:** Missing values are replaced with the mean of the available data for that variable. While this method retains all cases in the analysis, it can introduce bias by reducing the variability in the data. The consequence is that the standard errors and significance tests may be underestimated, leading to an increased risk of Type I errors (false positives).\n",
    "\n",
    "3. **Last Observation Carried Forward (LOCF):** In longitudinal studies, this method carries forward the last observed value for each subject to replace missing data points. While it maintains sample size, LOCF may not be appropriate if subjects' conditions change over time, leading to incorrect inferences.\n",
    "\n",
    "4. **Linear Interpolation:** In cases where the missing data points are assumed to follow a linear trend, you can interpolate missing values based on neighboring observations. This method retains sample size and can provide reasonable estimates if the linear assumption holds, but it may not be suitable for all datasets.\n",
    "\n",
    "5. **Multiple Imputation:** Multiple imputation generates multiple datasets, each with different imputed values for missing data, and combines results from these datasets. It is a robust method when data are missing at random (MAR) or MCAR, preserving sample size and accounting for uncertainty due to imputation. However, it can be computationally intensive and may require assumptions about the missing data mechanism.\n",
    "\n",
    "6. **Maximum Likelihood Estimation (MLE):** MLE estimates model parameters using all available information, including incomplete cases. It provides unbiased parameter estimates when data are missing at random (MAR) but requires specifying a model for the missing data mechanism. MLE is a sophisticated method but may not be straightforward to implement in all statistical software.\n",
    "\n",
    "The choice of method for handling missing data should depend on the nature and extent of missingness in your dataset, as well as the underlying assumptions about the missing data mechanism (e.g., MCAR, MAR). Multiple imputation and maximum likelihood estimation are generally preferred when data are missing at random, as they provide valid and efficient estimates while accounting for uncertainty. However, they may be more complex to implement than simpler methods like mean imputation.\n",
    "\n",
    "It's crucial to carefully consider the potential consequences of your chosen method and to report any missing data handling procedures transparently in your research to ensure the validity of your repeated measures ANOVA results. Additionally, sensitivity analyses can be performed to assess the robustness of your findings to different missing data handling strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f009ab4-7fe0-41d6-850e-083a3e76fd35",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b49ab-377a-49ac-92a7-7eefc5fd761d",
   "metadata": {},
   "source": [
    "Ans - After conducting an Analysis of Variance (ANOVA) and finding a significant difference among group means, post-hoc tests are often used to make pairwise comparisons between groups to determine which specific groups differ from each other. Common post-hoc tests include:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (Tukey's HSD):**\n",
    "   - **Use:** Tukey's HSD is used when you have conducted a one-way ANOVA and want to compare all possible pairs of group means. It controls the familywise error rate, making it suitable for maintaining an overall Type I error rate at a desired level.\n",
    "   - **Example:** In a study comparing the effects of three different treatments (A, B, C) on pain relief, the ANOVA indicates a significant difference among the treatments. Tukey's HSD can be used to identify which specific treatments are significantly different from each other.\n",
    "\n",
    "2. **Bonferroni Correction:**\n",
    "   - **Use:** The Bonferroni correction is a conservative approach to control the familywise error rate. It is applicable in situations where you have conducted multiple pairwise comparisons after an ANOVA. It adjusts the significance level for each test to keep the overall Type I error rate at the desired level (e.g., 0.05).\n",
    "   - **Example:** After conducting a one-way ANOVA, you want to perform several pairwise comparisons between groups. To maintain an overall significance level of 0.05, you apply the Bonferroni correction to adjust the significance level for each individual comparison.\n",
    "\n",
    "3. **Duncan's Multiple Range Test (MRT):**\n",
    "   - **Use:** Duncan's MRT is used to compare all possible pairs of group means in a one-way ANOVA. It does not control the familywise error rate like Tukey's HSD or Bonferroni, so it may be more powerful but can result in a higher Type I error rate.\n",
    "   - **Example:** In agricultural research, you want to compare the yields of several different fertilizer treatments (A, B, C, D). After an ANOVA, Duncan's MRT can be used to determine which specific fertilizers yield significantly different crop yields.\n",
    "\n",
    "4. **Scheffé's Test:**\n",
    "   - **Use:** Scheffé's test is a conservative post-hoc test that can be used in situations where you have unequal sample sizes and variances among groups. It controls the familywise error rate and is appropriate when the assumptions of homogeneity of variances are violated.\n",
    "   - **Example:** In a study comparing the performance of different teaching methods across multiple classrooms with varying numbers of students, Scheffé's test can be used to assess pairwise differences while accounting for the differences in sample sizes and variances.\n",
    "\n",
    "5. **Holm-Bonferroni Method:**\n",
    "   - **Use:** The Holm-Bonferroni method is a step-down procedure that adjusts the significance level for each pairwise comparison to control the familywise error rate. It is less conservative than Bonferroni and can be used when conducting multiple comparisons.\n",
    "   - **Example:** In a clinical trial with multiple treatment groups, the ANOVA shows a significant difference. The Holm-Bonferroni method can be used to determine which specific treatment pairs have statistically significant differences.\n",
    "\n",
    "The choice of post-hoc test depends on your specific research question, the design of your study, and your desired level of control over Type I errors. It's essential to select a post-hoc test that matches the assumptions and goals of your analysis. Failure to perform post-hoc tests can result in limited insight into where the significant differences lie among groups, which may be crucial for interpreting the results of your ANOVA accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63243da-71cf-47ff-b744-61f6882bb20e",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0e015-f3da-4adf-9d36-e3e2a1fcf04d",
   "metadata": {},
   "source": [
    "Ans - To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets (A, B, and C) with 50 participants each, you can use the scipy.stats library. Here's how you can perform the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dd7f1a-bcc3-4faa-9f1a-09cdf8e8f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 6.23\n",
      "P-value: 0.0025\n",
      "The p-value is less than the significance level.\n",
      "Reject the null hypothesis.\n",
      "There is at least one diet with a significantly different mean weight loss.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate sample data for each diet (mean weight loss)\n",
    "np.random.seed(0)  # For reproducibility\n",
    "data_A = np.random.normal(5, 2, 50)  # Diet A\n",
    "data_B = np.random.normal(6, 2, 50)  # Diet B\n",
    "data_C = np.random.normal(4, 2, 50)  # Diet C\n",
    "\n",
    "# Combine the data\n",
    "all_data = [data_A, data_B, data_C]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(*all_data)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "print(f\"F-statistic: {f_statistic:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level.\")\n",
    "    print(\"Reject the null hypothesis.\")\n",
    "    print(\"There is at least one diet with a significantly different mean weight loss.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to the significance level.\")\n",
    "    print(\"Fail to reject the null hypothesis.\")\n",
    "    print(\"There is no significant difference in mean weight loss among the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b92f58-898d-4e7b-9cad-c10938f53933",
   "metadata": {},
   "source": [
    "\n",
    "In this code:\n",
    "\n",
    "1. We generate random sample data for each diet, assuming a normal distribution with specified means (5, 6, and 4) and standard deviations (2).\n",
    "\n",
    "2. We combine the data from all three diets into the `all_data` list.\n",
    "\n",
    "3. We perform a one-way ANOVA using `stats.f_oneway` on the combined data to calculate the F-statistic and p-value.\n",
    "\n",
    "4. We interpret the results based on the significance level (alpha). If the p-value is less than alpha (0.05 in this case), we reject the null hypothesis, indicating that there is at least one diet with a significantly different mean weight loss.\n",
    "\n",
    "5. Finally, we print out the F-statistic, p-value, and the interpretation of the results.\n",
    "\n",
    "Please note that in a real study, you would replace the random data with your actual data collected from participants on each diet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16573b91-2ca7-4fee-b1c7-f8bdc40e35ab",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b14f0-adf9-4929-8322-03267965c775",
   "metadata": {},
   "source": [
    "Ans - To conduct a two-way ANOVA in Python to determine if there are any main effects or interaction effects between software programs (Program A, Program B, and Program C) and employee experience levels (novice vs. experienced) on task completion time, you can use the \"statsmodels\" library. Here's how you can perform the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce84d057-6817-4568-aac8-9b229fb9b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Software: 2.11381360335568\n",
      "Main Effect of Experience: 0.7976521470238848\n",
      "Interaction Effect: 1.14085719952035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "# Create a dataframe with software programs, experience levels, and task completion times\n",
    "data = {'Software': np.random.choice(['A', 'B', 'C'], 30),\n",
    "        'Experience': np.random.choice(['Novice', 'Experienced'], 30),\n",
    "        'Time': np.random.normal(10, 2, 30)}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "formula = 'Time ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_software = anova_table.loc['C(Software)', 'F']\n",
    "main_effect_experience = anova_table.loc['C(Experience)', 'F']\n",
    "interaction_effect = anova_table.loc['C(Software):C(Experience)', 'F']\n",
    "\n",
    "# Print results\n",
    "print(\"Main Effect of Software:\", main_effect_software)\n",
    "print(\"Main Effect of Experience:\", main_effect_experience)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edfc01e-bf9e-4fbe-b340-d06e1a95220f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this code:\n",
    "\n",
    "1. We generate random sample data for the software programs, experience levels, and task completion times.\n",
    "\n",
    "2. We create a dataframe (`df`) to organize the data, with columns for software, experience, and time.\n",
    "\n",
    "3. We fit a two-way ANOVA model using `statsmodels`, specifying both main effects and the interaction effect in the formula.\n",
    "\n",
    "4. We extract the F-statistics for the main effect of software, main effect of experience, and the interaction effect from the ANOVA table.\n",
    "\n",
    "5. Finally, we print out the main effects and interaction effect.\n",
    "\n",
    "Interpreting the results:\n",
    "\n",
    "- Main Effect of Software: This represents whether there are significant differences in task completion times among the software programs, regardless of employee experience. A significant F-statistic and a small p-value suggest that software choice has a significant impact on task completion time.\n",
    "\n",
    "- Main Effect of Experience: This indicates whether there are significant differences in task completion times between novice and experienced employees, regardless of the software used. A significant F-statistic and a small p-value suggest that employee experience level has a significant impact on task completion time.\n",
    "\n",
    "- Interaction Effect: This term assesses whether the combination of software and experience level has a significant impact on task completion time beyond what can be explained by the main effects. A significant interaction effect suggests that the effect of software on task completion time depends on the experience level, or vice versa.\n",
    "\n",
    "To interpret the results further, you can examine the p-values associated with each effect. If the p-values are below your chosen significance level (e.g., 0.05), you would conclude that the corresponding effect is significant. Additionally, you can perform post hoc tests or pairwise comparisons to investigate specific differences between software programs and experience levels if significant effects are found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f7e8f-5fae-4ae7-bfcb-8f49156ed359",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c0508-5afb-4e17-9dd7-242f64f27077",
   "metadata": {},
   "source": [
    "Ans - To determine if there are significant differences in test scores between two groups (control group with the traditional teaching method and experimental group with the new teaching method), you can conduct a two-sample t-test in Python. If the results are significant, you can follow up with post-hoc tests, such as pairwise comparisons, to identify which group(s) differ significantly. Here's how you can perform these analyses:\n",
    "\n",
    "1.Two-Sample T-Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454ee6a8-8a22-4753-8b99-7e386d2fc643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "T-statistic: -3.60\n",
      "P-value: 0.0004\n",
      "The p-value is less than the significance level.\n",
      "Reject the null hypothesis.\n",
      "There is a significant difference in test scores between the two groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate sample data for the control and experimental groups\n",
    "np.random.seed(0)  # For reproducibility\n",
    "control_group = np.random.normal(75, 10, 100)  # Control group (traditional method)\n",
    "experimental_group = np.random.normal(80, 10, 100)  # Experimental group (new method)\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(f\"T-statistic: {t_statistic:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than the significance level.\")\n",
    "    print(\"Reject the null hypothesis.\")\n",
    "    print(\"There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to the significance level.\")\n",
    "    print(\"Fail to reject the null hypothesis.\")\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc2291-e10b-4bb4-a1aa-741164a376d5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "In this code:\n",
    "\n",
    "- We generate random sample data for the control and experimental groups using normal distributions with specified means (75 and 80) and standard deviations (10).\n",
    "\n",
    "- We perform a two-sample t-test using `stats.ttest_ind` to compare the means of the two groups.\n",
    "\n",
    "- We interpret the results based on the significance level (alpha) and print whether there is a significant difference in test scores between the two groups.\n",
    "\n",
    "2. **Post-Hoc Tests (Pairwise Comparisons):**\n",
    "\n",
    "If the two-sample t-test results indicate a significant difference between the groups, you can perform post-hoc tests to identify which group(s) differ significantly. You can use the `statsmodels` library for pairwise comparisons. Here's an example of how to do it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dbf799-bf8a-49fd-b0e6-becfe4381698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Tukey's HSD Post-Hoc Test Results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental    5.222 0.0004 2.3593 8.0848   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine data from both groups\n",
    "all_data = np.concatenate([control_group, experimental_group])\n",
    "\n",
    "# Create a grouping variable to indicate control and experimental groups\n",
    "group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
    "\n",
    "# Perform pairwise Tukey's HSD post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(all_data, group_labels, alpha=0.05)\n",
    "\n",
    "# Print pairwise comparisons\n",
    "print(\"Pairwise Tukey's HSD Post-Hoc Test Results:\")\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf57b6-8b5c-4a42-9f18-1652576f1d23",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "- We combine data from both groups into a single array ('all_data').\n",
    "\n",
    "- We create a grouping variable ('group_labels') to indicate the control and experimental groups.\n",
    "\n",
    "- We perform pairwise Tukey's HSD post-hoc tests using 'pairwise_tukeyhsd' to compare the means of the two groups and print the results.\n",
    "\n",
    "The results of the post-hoc test will show which group(s) differ significantly from each other if there are significant differences in test scores between the control and experimental groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e2de38-199d-4765-917c-3e9a2b45c679",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9e3fa-cdec-4dad-9405-4f1907a273f8",
   "metadata": {},
   "source": [
    "Ans - A repeated measures ANOVA is typically used when you have dependent measurements taken on the same subjects or units across multiple time points or conditions. In your scenario, where you want to compare the average daily sales of three retail stores (Store A, Store B, and Store C) across 30 days, you may want to use a one-way repeated measures ANOVA since you have one independent variable (store) with multiple repeated measurements (days).\n",
    "\n",
    "Here's how you can conduct a one-way repeated measures ANOVA in Python and follow up with a post-hoc test if the results are significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d8e3a0-1ca1-4781-92bd-78ee7313f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Measures ANOVA Results:\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 10.4819 2.0000 58.0000 0.0001\n",
      "===================================\n",
      "\n",
      "\n",
      "Pairwise Tukey's HSD Post-Hoc Test Results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1  group2 meandiff p-adj   lower    upper   reject\n",
      "--------------------------------------------------------\n",
      "Store_A Store_B  10.4859   0.71 -21.1512   42.123  False\n",
      "Store_A Store_C -48.1603 0.0014 -79.7974 -16.5232   True\n",
      "Store_B Store_C -58.6461 0.0001 -90.2832  -27.009   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "# Create a dataframe with daily sales data for each store\n",
    "data = {'Day': np.arange(1, 31),\n",
    "        'Store_A': np.random.normal(500, 50, 30),  # Store A\n",
    "        'Store_B': np.random.normal(550, 60, 30),  # Store B\n",
    "        'Store_C': np.random.normal(480, 45, 30)}  # Store C\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Reshape the data for repeated measures ANOVA\n",
    "df_melted = pd.melt(df, id_vars=['Day'], value_vars=['Store_A', 'Store_B', 'Store_C'],\n",
    "                     var_name='Store', value_name='Sales')\n",
    "\n",
    "# Fit a repeated measures ANOVA model\n",
    "rm_anova = AnovaRM(df_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "\n",
    "# Print repeated measures ANOVA results\n",
    "print(\"Repeated Measures ANOVA Results:\")\n",
    "print(rm_results)\n",
    "\n",
    "# Follow up with a post-hoc test (e.g., Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(df_melted['Sales'], df_melted['Store'], alpha=0.05)\n",
    "print(\"\\nPairwise Tukey's HSD Post-Hoc Test Results:\")\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17f73d-3188-4d8b-9b4e-10ee4d3fc467",
   "metadata": {},
   "source": [
    "\n",
    "In this code:\n",
    "\n",
    "- We generate sample daily sales data for each store across 30 days, assuming normal distributions with specified means and standard deviations.\n",
    "\n",
    "- We reshape the data into long format using `pd.melt` to prepare it for repeated measures ANOVA.\n",
    "\n",
    "- We fit a repeated measures ANOVA model using `AnovaRM` from the `statsmodels` library, specifying 'Sales' as the dependent variable, 'Day' as the repeated measure, and 'Store' as the within-subject factor.\n",
    "\n",
    "- We print the repeated measures ANOVA results to assess whether there are significant differences in sales between the three stores.\n",
    "\n",
    "- If the results are significant, we follow up with a post-hoc test (e.g., Tukey's HSD) to determine which store(s) differ significantly from each other.\n",
    "\n",
    "The post-hoc test results will indicate which store pairs have significant differences in daily sales if the repeated measures ANOVA results are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673ffdb-b17e-443a-ad61-17e80aabb1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
